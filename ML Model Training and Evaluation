###   STEP :- 8 (Machine Learning Model Evaluations and Predictions)   ###


install.packages("class", dependencies = TRUE)
library(class)


#   KNN(K-Nearest Neighbours) Algorithm   #


                          # Define the number of neighbors
k <- 11

                          # Train the k-NN model and predict on test data
predicted_y <- knn(
  train = X_train,            # Training data (features)
  test = X_test,              # Test data (features)
  cl = y_train,               # Training labels
  k = k                       # Number of neighbors
)

                                             # Calculate accuracy
accuracy_knn <- mean(predicted_y == y_test)  # Compare predictions with actual test labels

print(paste("KNN Accuracy :-", accuracy_knn))

                                            # Convert y_test and predicted_y to factors (if they are not already)
y_test <- as.factor(y_test)
predicted_y <- as.factor(predicted_y)

                                            # Create a confusion matrix
conf_matrix <- confusionMatrix(predicted_y, y_test)

                                            # Print classification report
print(conf_matrix)

 
#   SVM (Support Vector Machine) Algorithm   #


install.packages("e1071")
library(e1071)

# (Train an SVM model)
svc_model <- svm(
  x = X_train,            # Training features
  y = as.factor(y_train), # Training labels (as factor)
  kernel = "linear",      # Kernel type (linear, polynomial, radial, sigmoid)
  probability = TRUE,     # Enable probability predictions
  random.seed = 1         # Set random state equivalent
)

                                           # Predict on test data
predict_y <- predict(svc_model, X_test)

                                           # Calculate accuracy
accuracy_svc <- mean(predict_y == y_test)  # Compare predictions with actual labels

print(paste("SVM Accuracy :- ", accuracy_svc))

# (Convert y_test and predict_y to factors (if not already) )
y_test <- as.factor(y_test)
predict_y <- as.factor(predict_y)

              # Create a confusion matrix
conf_matrix <- confusionMatrix(predict_y, y_test)

              # Print the classification report
print(conf_matrix)


#   RANDOM FOREST Algorithm   #


install.packages("randomForest")
library(randomForest)

# Train a Random Forest model
model_rf <- randomForest(
  x = X_train,                    # Training features
  y = as.factor(y_train),         # Training labels (as factor)
  ntree = 500,                    # Number of trees
  mtry = sqrt(ncol(X_train)),     # Number of features to consider at each split (equivalent to "auto")
  maxnodes = 30,                  # Maximum number of leaf nodes
  strata = as.factor(y_train),    # Stratified sampling by class
  sampsize = c(573, 573),         # Balanced sample size
  importance = TRUE,              # Calculate feature importance
  oob.score = TRUE,               # Use out-of-bag samples for error estimation
  #do.trace = 50                   # Progress output
)

# Print OOB score
print(paste("Out-of-Bag (OOB) Score :- ", model_rf$err.rate[nrow(model_rf$err.rate), 1]))

# Make predictions on the test set
prediction_test <- predict(model_rf, X_test)

accuracy <- mean(prediction_test == y_test)
print(paste("RANDOM FOREST Accuracy :- ", accuracy))


# (Classification Report)

y_test <- as.factor(y_test)
prediction_test <- as.factor(prediction_test)

# Create a confusion matrix
conf_matrix <- confusionMatrix(prediction_test, y_test)

# Print the classification report
print(conf_matrix)


#  (RANDOM FOREST Confusion Matrix)

conf_matrix <- table(Predicted = prediction_test, Actual = y_test)

conf_df <- as.data.frame(as.table(conf_matrix))

ggplot(conf_df, aes(x = Predicted, y = Actual, fill = Freq)) +
  geom_tile(color = "black", linewidth = 0.8) + 
  geom_text(aes(label = Freq), size = 5, color = "white") +  
  scale_fill_gradient(low = "lightblue", high = "blue") +  
  labs(
    title = "RANDOM FOREST CONFUSION MATRIX",
    x = "Predicted",
    y = "Actual"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.text.x = element_text(size = 10),
    axis.text.y = element_text(size = 10)
  )


#   Random Forest ROC Curve   #


install.packages("pROC")
library(pROC)

# Predict probabilities for the test set
y_rfpred_prob <- predict(model_rf, X_test, type = "prob")[, 2]  # Probability for class '1'

# Calculate ROC curve
roc_rf <- roc(y_test, y_rfpred_prob)

# Extract False Positive Rate (FPR) and True Positive Rate (TPR)
fpr_rf <- 1 - roc_rf$specificities
tpr_rf <- roc_rf$sensitivities

roc_df <- data.frame(FPR = fpr_rf, TPR = tpr_rf)

# Plot the ROC curve using ggplot2
ggplot(roc_df, aes(x = FPR, y = TPR)) +
  geom_line(color = "red", size = 1) +                                           # ROC curve in red
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") +  # Diagonal reference line
  labs(
    title = "Random Forest ROC Curve",
    x = "False Positive Rate",
    y = "True Positive Rate"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 12)
  )



#   LOGISTIC REGRESSION   #

install.packages("caret")
install.packages("glmnet")
install.packages("ROSE")                   # For Over Sampling / Under Sampling

library(caret)
library(glmnet)
library(ROSE)

#  (Data Preprocessing (Scaling))  #

                                  # Scale the data (numerical features only)
X_train_scaled <- as.data.frame(scale(X_train))
X_test_scaled <- as.data.frame(scale(X_test))

                                  # Encode categorical variables (One-Hot Encoding)
X_train_encoded <- model.matrix(~ . - 1, data = X_train)  # Remove intercept
X_test_encoded <- model.matrix(~ . - 1, data = X_test)


#  (Checking Class Imbalance and balancing DATA)  #


                                  # Check class distribution
print(table(y_train))

                                  # Apply oversampling using ROSE
balanced_train <- ovun.sample(
  Churn ~ ., 
  data = cbind(X_train, Churn = y_train), 
  method = "over", 
  N = 2 * table(y_train)[1]
)$data

                                  # Split balanced data back into X_train and y_train
X_train_balanced <- balanced_train[, colnames(X_train)]
y_train_balanced <- balanced_train$Churn


#  (Model Training)  #


# Prepare the data for glmnet
X_train_matrix <- as.matrix(scale(X_train_balanced))  
y_train_binary <- as.numeric(as.factor(y_train_balanced)) - 1 

# Perform cross-validation to find the best lambda
cv_fit <- cv.glmnet(
  X_train_matrix, 
  y_train_binary, 
  alpha = 0,  # L2 regularization
  family = "binomial", 
  nfolds = 10
)

# Extract the best lambda
best_lambda <- cv_fit$lambda.min
print(paste("Best Lambda :- ", best_lambda))


#  (Model Prediction and Evaluation)  #


# Train the final model using the best lambda
final_model <- glmnet(
  X_train_matrix, 
  y_train_binary, 
  alpha = 0, 
  family = "binomial", 
  lambda = best_lambda
)

# Predict probabilities on the test set
X_test_matrix <- as.matrix(scale(X_test))
y_pred_prob <- predict(final_model, newx = X_test_matrix, type = "response")

# Convert probabilities to class predictions
y_pred <- ifelse(y_pred_prob > 0.5, 1, 0)

# Calculate accuracy
accuracy <- mean(y_pred == y_test)
print(paste("Logistic Regression (GLM) Accuracy :- ", accuracy))


#  (Classification Report)  #

# Ensure y_pred and y_test are factors
y_pred <- as.factor(y_pred)
y_test <- as.factor(y_test)

# Generate confusion matrix and classification report
conf_matrix <- confusionMatrix(y_pred, y_test)

# Print the classification report
print(conf_matrix)


#  (Logistic Regression - Confusion Matrix)  #


conf_matrix <- table(Predicted = y_pred, Actual = y_test)
                                      # Convert the confusion matrix to a data frame for ggplot
conf_df <- as.data.frame(as.table(conf_matrix))

# Create the heatmap using ggplot2
ggplot(conf_df, aes(x = Predicted, y = Actual, fill = Freq)) +
  geom_tile(color = "black", linewidth = 1) +                
  geom_text(aes(label = Freq), size = 5, color = "white") + 
  scale_fill_gradient(low = "blue", high = "red") +          
  labs(
    title = "Logistic Regression Confusion Matrix",
    x = "Predicted",
    y = "Actual"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )


#  (Logistic Regression - ROC Curve)  #


# Calculate the ROC curve
roc_curve <- roc(y_test, y_pred_prob)  # y_test (true labels) and y_pred_prob (predicted probabilities)

# Extract False Positive Rate (1 - Specificity) and True Positive Rate (Sensitivity)
fpr <- 1 - roc_curve$specificities
tpr <- roc_curve$sensitivities

# Create a data frame for ggplot
roc_df <- data.frame(FPR = fpr, TPR = tpr)

# Plot the ROC curve using ggplot2
ggplot(roc_df, aes(x = FPR, y = TPR)) +
  geom_line(color = "red", size = 1) +                          
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +  
  labs(
    title = "Logistic Regression ROC Curve",
    x = "False Positive Rate",
    y = "True Positive Rate"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )


#  DECISION TREE  #

 
install.packages("rpart")
install.packages("caret")                      # For accuracy and evaluation
library(rpart)
library(caret)

# Train the Decision Tree model
dt_model <- rpart(
  Churn ~ .,                              # Formula: Churn as a function of all features
  data = cbind(X_train, Churn = y_train), # Combine features and labels
  method = "class"                        # Classification method
)

# Predict on the test set
predictdt_y <- predict(dt_model, newdata = X_test, type = "class")

# Calculate accuracy
accuracy_dt <- mean(predictdt_y == y_test)
print(paste("Decision Tree Accuracy :- ", accuracy_dt))


#  (CLASSIFICATION Report)  #


# Ensure predictions and true labels are factors
predictdt_y <- as.factor(predictdt_y)
y_test <- as.factor(y_test)

# Generate the confusion matrix and classification report
conf_matrix <- confusionMatrix(predictdt_y, y_test)

# Print the classification report
print(conf_matrix)



#   XG BOOST CLASSIFIER   #


install.packages("xgboost")
library(xgboost)

# Convert the training and test data to matrices
X_train_matrix <- as.matrix(X_train)
X_test_matrix <- as.matrix(X_test)

# Convert labels to numeric (required by xgboost)
y_train_numeric <- as.numeric(as.factor(y_train)) - 1  # Convert to 0/1
y_test_numeric <- as.numeric(as.factor(y_test)) - 1    # Convert to 0/1


# Create DMatrix objects for training and testing
dtrain <- xgb.DMatrix(data = X_train_matrix, label = y_train_numeric)
dtest <- xgb.DMatrix(data = X_test_matrix, label = y_test_numeric)

# Train the model
a_model <- xgboost(
  data = dtrain, 
  max_depth = 1,               # Depth of 1 mimics AdaBoost's decision stumps
  eta = 1,                     # High learning rate to mimic AdaBoost
  nrounds = 50,                # Number of boosting iterations
  objective = "binary:logistic", # Binary classification
  verbose = 1                  # Show training progress
)


# Predict probabilities
a_preds_prob <- predict(a_model, dtest)

# Convert probabilities to binary predictions
a_preds <- ifelse(a_preds_prob > 0.5, 1, 0)

# Calculate accuracy
accuracy <- mean(a_preds == y_test_numeric)
print(paste("AdaBoost-Like Model Accuracy :-", accuracy))


#  (Classification Report)  #


# Ensure predictions and true labels are factors
a_preds <- as.factor(a_preds)
y_test <- as.factor(y_test_numeric)

# Generate confusion matrix and classification report
conf_matrix <- confusionMatrix(a_preds, y_test)

# Print the classification report
print(conf_matrix)


#  (Confusion Matrix)  #


# Generate the confusion matrix
conf_matrix <- table(Predicted = a_preds, Actual = y_test)

# Convert the confusion matrix to a data frame for ggplot
conf_df <- as.data.frame(as.table(conf_matrix))

# Create the heatmap using ggplot2
ggplot(conf_df, aes(x = Predicted, y = Actual, fill = Freq)) +
  geom_tile(color = "black", linewidth = 1) +                # Add gridlines to heatmap
  geom_text(aes(label = Freq), size = 5, color = "white") +  # Annotate the cells
  scale_fill_gradient(low = "blue", high = "red") +          # Gradient color for cells
  labs(
    title = "XGBoost Confusion Matrix",
    x = "Predicted",
    y = "Actual"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )


##########            END OF CODE          ##########
